{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment and data mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "train_folder = 'data/train/'\n",
    "labels = {'pos': 1, 'neg': 0}\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "   \n",
    "for l in ('pos', 'neg'):\n",
    "    path = os.path.join(train_folder, l)\n",
    "    for file in os.listdir (path) :\n",
    "        with open(os.path.join(path, file),'r', encoding='utf-8') as infile:\n",
    "            txt = infile.read()\n",
    "        train_data = train_data.append([[txt, labels[l]]],ignore_index=True)\n",
    "train_data.columns = ['review', 'sentiment']\n",
    "train_data.to_csv('data/train_data.csv', sep=',', encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "test_folder = 'data/test/'\n",
    "test_data = pd.DataFrame()  \n",
    "for l in ('pos', 'neg'):\n",
    "    path = os.path.join(test_folder, l)\n",
    "    for file in os.listdir (path) :\n",
    "        with open(os.path.join(path, file),'r', encoding='utf-8') as infile:\n",
    "            txt = infile.read()\n",
    "        test_data = test_data.append([[txt, labels[l]]],ignore_index=True)\n",
    "test_data.columns =  ['review', 'sentiment']\n",
    "test_data.to_csv('data/test_data.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    For a movie that gets no respect there sure ar...\n",
      "1    Bizarre horror movie filled with famous faces ...\n",
      "2    A solid, if unremarkable film. Matthau, as Ein...\n",
      "3    It's a strange feeling to sit alone in a theat...\n",
      "4    You probably all already know this by now, but...\n",
      "Name: review, dtype: object\n",
      "0    Based on an actual story, John Boorman shows t...\n",
      "1    This is a gem. As a Film Four production - the...\n",
      "2    I really like this show. It has drama, romance...\n",
      "3    This is the best 3-D experience Disney has at ...\n",
      "4    Of the Korean movies I've seen, only three had...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv', sep=',', encoding='utf-8', header=0)\n",
    "test_data = pd.read_csv('data/test_data.csv', sep=',', encoding='utf-8', header=0)\n",
    "\n",
    "print(train_data['review'].head())\n",
    "print(test_data['review'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    For a movie that gets no respect there sure ar...\n",
      "1    Bizarre horror movie filled with famous faces ...\n",
      "2    A solid, if unremarkable film. Matthau, as Ein...\n",
      "3    It's a strange feeling to sit alone in a theat...\n",
      "4    You probably all already know this by now, but...\n",
      "Name: review, dtype: object\n",
      "0    Based on an actual story, John Boorman shows t...\n",
      "1    This is a gem. As a Film Four production - the...\n",
      "2    I really like this show. It has drama, romance...\n",
      "3    This is the best 3-D experience Disney has at ...\n",
      "4    Of the Korean movies I've seen, only three had...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_reviews(review):\n",
    "    review = REPLACE_NO_SPACE.sub(\"\", review.lower())\n",
    "    review = REPLACE_WITH_SPACE.sub(\" \", review)\n",
    "    review = tokenizer.tokenize(review)\n",
    "    \n",
    "    review = [i for i in review if not i in STOPWORDS]\n",
    "\n",
    "    # stem tokens\n",
    "    review = [stemmer.stem(i) for i in review]\n",
    "    \n",
    "    \n",
    "    return(\" \".join(review)) \n",
    "\n",
    "\n",
    "x_train = train_data['review'].copy().apply(preprocess_reviews)\n",
    "y_train = train_data['sentiment']\n",
    "x_test = test_data['review'].copy().apply(preprocess_reviews)\n",
    "y_test = train_data['sentiment']\n",
    "print(train_data['review'].head())\n",
    "print(test_data['review'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(analyzer='word', ngram_range=(2,2), min_df = 1, max_df = 1)\n",
    "\n",
    "movie_counts = cv.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "movie_tfidf = tfidf_transformer.fit_transform(movie_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8331    0.8936    0.8623     12500\n",
      "           1     0.8853    0.8210    0.8519     12500\n",
      "\n",
      "   micro avg     0.8573    0.8573    0.8573     25000\n",
      "   macro avg     0.8592    0.8573    0.8571     25000\n",
      "weighted avg     0.8592    0.8573    0.8571     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "review_clf = Pipeline([('vect', CountVectorizer(analyzer='word', ngram_range=(2,2), min_df = 0)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(2, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': [1, 1e-1, 1e-2]\n",
    "}\n",
    "clf = GridSearchCV(review_clf, parameters, cv=5)\n",
    "clf.fit(x_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(x_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.85732\n",
      "F1 Score 0.8519486987921804\n"
     ]
    }
   ],
   "source": [
    "# output the scores again for improved model\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "predictions = clf.predict(x_test)\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test,predictions))\n",
    "print(\"F1 Score\", f1_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "Get some wrongly classified reviews which are not alonger then 500 chars long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review  sentiment  predicted\n",
      "11333  This is my favorite Mel Brooks movie because i...          1          0\n",
      "23618  To begin with its a rip off of the Japanese fi...          0          1\n",
      "738    I just wanted to say that. I love Gheorghe Mur...          1          0\n",
      "21719  This movie is overrated, to say the least. It'...          0          1\n",
      "12114  Fate puts a pair of priceless items in Ernest'...          1          0\n"
     ]
    }
   ],
   "source": [
    "predicted_frame = pd.DataFrame(predictions, columns=[\"predicted\"])\n",
    "act_pred_frame = pd.concat([test_data[\"review\"],test_data[\"sentiment\"],predicted_frame[\"predicted\"]], axis=1)\n",
    "act_pred_frame = act_pred_frame[act_pred_frame[\"review\"].str.len() <= 500]\n",
    "sampled_wrong_class = act_pred_frame[act_pred_frame[\"sentiment\"] != \n",
    "                                     act_pred_frame[\"predicted\"]].sample(frac=1).head()\n",
    "print(sampled_wrong_class.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lime for easy understanding why something got wrongly classified\n",
    "from lime import lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "class_names = ['negative','positive']\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "for index, row in sampled_wrong_class.iterrows():\n",
    "    exp = explainer.explain_instance(x_test[index], clf.predict_proba)\n",
    "    path = 'lime/' + str(index) + '.html'\n",
    "    exp.save_to_file(path, text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Predict unlabeled reviews (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_folder = 'data/train/unsup'\n",
    "unlabeled_data = pd.DataFrame() \n",
    "path = os.path.join(unlabeled_folder)\n",
    "for file in os.listdir (path) :\n",
    "    with open(os.path.join(path, file),'r', encoding='utf-8') as infile:\n",
    "        txt = infile.read()\n",
    "    unlabeled_data = unlabeled_data.append([[txt]],ignore_index=True)\n",
    "unlabeled_data.columns = ['review']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unlabeled = unlabeled_data['review'].copy().apply(preprocess_reviews)\n",
    "unlbl_predictions = clf.predict(x_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlbl_predictions_frame = pd.DataFrame(unlbl_predictions, columns=[\"predicted\"])\n",
    "act_pred_frame = pd.concat([unlabeled_data[\"review\"],unlbl_predictions_frame[\"predicted\"]], axis=1)\n",
    "unlbl_predictions_frame.to_csv('data/unlabeled_predictions.csv', sep=',', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
